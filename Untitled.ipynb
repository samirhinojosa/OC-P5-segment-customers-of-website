{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01fb88d-4006-4ba6-b30d-d1f8f74600eb",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: #3F579F;\">\n",
    "    <h1 style=\"margin: auto; font-weight: bold; padding: 30px 30px 0px 30px;\" align=\"center\">Segment customers of a website - P5</h1>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 5px 30px 0px 30px;\" >\n",
    "    <h3 style=\"width: 100%; text-align: center; float: left; font-size: 24px;\" align=\"center\">| Analysis notebook |</h3>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 10px 30px 30px 30px;\">\n",
    "    <h4 style=\"width: 100%; text-align: center; float: left; font-size: 24px;\" align=\"center\">Data Scientist course - OpenClassrooms</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbce629-1449-4c34-8104-26c86c4ad6c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">1. Libraries and functions</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb589b76-9cbc-4a11-be10-30ce9ad7fc8f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">1.1. Libraries and functions</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71c1574-0703-4677-8ed7-6a9ef6df38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## df_analysis\n",
    "import io\n",
    "import gc\n",
    "import timeit\n",
    "import math\n",
    "from math import pi\n",
    "from collections import Counter\n",
    "from math import prod\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "SUB = str.maketrans(\"0123456789\", \"₀₁₂₃₄₅₆₇₈₉\")\n",
    "SUP = str.maketrans(\"0123456789\", \"⁰¹²³⁴⁵⁶⁷⁸⁹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65671d-f05c-4c4f-b118-554474e3f963",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">1.2. Functions declaration</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4ae76f-4384-44bf-809c-09bebcf76b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_analysis(df, name_df, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Method used to analyze on the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): Dataset to analyze\n",
    "        name_df (str): Dataset name\n",
    "        \n",
    "        *args, **kwargs:\n",
    "        -----------------\n",
    "            columns (list): Dataframe keys in list format\n",
    "            flag (str): Flag to show complete information about the dataset to analyse\n",
    "                        \"complete\" shows all information about the dataset\n",
    "\n",
    "    Returns:\n",
    "    -----------------\n",
    "        None. \n",
    "        Print the analysis on the Dataset. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting the variables\n",
    "    columns = kwargs.get(\"columns\", None)\n",
    "    type_analysis = kwargs.get(\"type_analysis\", None)\n",
    "    \n",
    "    ORDERING_COMPLETE = [\n",
    "        \"name\", \"type\", \"records\", \"unique\", \"# NaN\", \"% NaN\", \"mean\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"std\"\n",
    "    ]\n",
    "    \n",
    "    # Calculating the memory usage based on dataframe.info()\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    memory_usage = buf.getvalue().split('\\n')[-2]\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"The\", name_df, \"dataset is empty. Please verify the file.\")\n",
    "    else:\n",
    "        empty_cols = [col for col in df.columns if df[col].isna().all()] # identifying empty columns\n",
    "        df_rows_duplicates = df[df.duplicated()] #identifying full duplicates rows\n",
    "        \n",
    "        # Creating a dataset based on Type object and records by columns\n",
    "        type_cols = df.dtypes.apply(lambda x: x.name).to_dict() \n",
    "        df_resume = pd.DataFrame(list(type_cols.items()), columns = [\"name\", \"type\"])\n",
    "        df_resume[\"records\"] = list(df.count())\n",
    "        df_resume[\"# NaN\"] = list(df.isnull().sum())\n",
    "        df_resume[\"% NaN\"] = list(((df.isnull().sum() / len(df.index))*100).round(2))\n",
    "        \n",
    "        print(\"\\nAnalysis of\", name_df, \"dataset\")\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "        print(\"- Dataset shape:                 \", df.shape[0], \"rows and\", df.shape[1], \"columns\")\n",
    "        print(\"- Total of NaN values:           \", df.isna().sum().sum())\n",
    "        print(\"- Percentage of NaN:             \", round((df.isna().sum().sum() / prod(df.shape)) * 100, 2), \"%\")\n",
    "        print(\"- Total of full duplicates rows: \", df_rows_duplicates.shape[0])\n",
    "        print(\"- Total of empty rows:           \", df.shape[0] - df.dropna(axis=\"rows\", how=\"all\").shape[0]) if df.dropna(axis=\"rows\", how=\"all\").shape[0] < df.shape[0] else \\\n",
    "                    print(\"- Total of empty rows:            0\")\n",
    "        print(\"- Total of empty columns:        \", len(empty_cols))\n",
    "        print(\"  + The empty column is:         \", empty_cols) if len(empty_cols) == 1 else \\\n",
    "                    print(\"  + The empty column are:         \", empty_cols) if len(empty_cols) >= 1 else None\n",
    "        print(\"- Unique indexes:                \", df.index.is_unique)\n",
    "        \n",
    "        if columns is not None:\n",
    "            print(\"\\n- The key(s):\", columns, \"is not present multiple times in the dataframe.\\n  It CAN be used as a primary key.\") if df.size == df.drop_duplicates(columns).size else \\\n",
    "                print(\"\\n- The key(s):\", columns, \"is present multiple times in the dataframe.\\n  It CANNOT be used as a primary key.\")\n",
    "            \n",
    "        if type_analysis == \"summarized\":\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if type_analysis is None or type_analysis != \"summarized\":\n",
    "            pd.set_option(\"display.max_rows\", None) # show full of showing rows\n",
    "            pd.set_option(\"display.max_columns\", None) # show full of showing cols\n",
    "            pd.set_option(\"display.max_colwidth\", None) # show full width of showing cols\n",
    "            pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x) # show full content in cell    \n",
    "            \n",
    "            if type_analysis is None or type_analysis != \"complete\":\n",
    "                print(\"\\n- Type object and records by columns      (\",memory_usage,\")\")\n",
    "                print(\"--------------------------------------------------------------------\")\n",
    "            elif type_analysis == \"complete\" and (df.select_dtypes([\"int64\"]).shape[1] > 0 or df.select_dtypes([\"float64\"]).shape[1] > 0):\n",
    "                df_resume[\"unique\"] = list(df.nunique())\n",
    "                df_desc = pd.DataFrame(df.describe().T).reset_index()\n",
    "                df_desc = df_desc.rename(columns={\"index\": \"name\"})\n",
    "                df_resume = df_resume.merge(right=df_desc[[\"name\", \"mean\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"std\"]], on=\"name\", how=\"left\")\n",
    "                df_resume = df_resume[ORDERING_COMPLETE]\n",
    "                print(\"\\n- Type object and records by columns      (\",memory_usage,\")\")\n",
    "                print(\"--------------------------------------------------------------------\")\n",
    "            \n",
    "            display(df_resume.sort_values(\"records\", ascending=False))\n",
    "            \n",
    "            pd.reset_option(\"display.max_rows\") # reset max of showing rows\n",
    "            pd.reset_option(\"display.max_columns\") # reset max of showing cols\n",
    "            pd.reset_option(\"display.max_colwidth\") # reset width of showing cols\n",
    "            pd.reset_option(\"display.float_format\") # reset show full content in cell\n",
    "            \n",
    "        # deleting dataframe to free memory\n",
    "        if type_analysis == \"complete\":\n",
    "            \n",
    "            if df.select_dtypes([\"int64\"]).shape[1] > 0 or df.select_dtypes([\"float64\"]).shape[1] > 0:\n",
    "                del [[df_resume, df_desc]]\n",
    "            else:\n",
    "                del [[df_resume]]\n",
    "            \n",
    "            gc.collect()\n",
    "            df_resume, df_desc = (pd.DataFrame() for i in range(2))\n",
    "        else:\n",
    "            del df_resume\n",
    "            gc.collect()\n",
    "            df_resume = pd.DataFrame()\n",
    "            \n",
    "\n",
    "def normality_test(df):\n",
    "    \"\"\"\n",
    "    Method used to make the normality test.\n",
    "\n",
    "    Parameters:\n",
    "    -----------------\n",
    "        df (pandas.DataFrame): Dataset to analyze\n",
    "\n",
    "    Returns:\n",
    "    -----------------\n",
    "        None. \n",
    "        Print the tests on a new Dataset. \n",
    "    \"\"\"\n",
    "    \n",
    "    list_test = {\n",
    "        \"Shapiro-Wilk\":stats.shapiro, \"D’Agostino’s K^2\":stats.normaltest,\n",
    "        \"Kolmogorov-Smirnov\":stats.kstest\n",
    "    }\n",
    "    \n",
    "    \n",
    "    alpha = 0.05\n",
    "    fail_to_reject_H = \"Sample looks Gaussian (fail to reject H0)\"\n",
    "    reject_H = \"Sample does not look Gaussian (reject H0)\"\n",
    "    \n",
    "    variable, test_name, result, hypothesis = [[] for i in range(4)]\n",
    "    \n",
    "    for key, value in list_test.items():\n",
    "    \n",
    "        for col in df.columns:\n",
    "            \n",
    "            if df[col].dtypes == \"float64\" or df[col].dtypes == \"int64\":\n",
    "                variable.append(col)\n",
    "                test_name.append(key)\n",
    "                \n",
    "                if key == \"Kolmogorov-Smirnov\":\n",
    "                    stat, p_value = value(df[col], cdf=\"norm\")\n",
    "                else:\n",
    "                    stat, p_value = value(df[col])\n",
    "                    \n",
    "                result.append(\"Statistics=%.3f, p-value=%.3f\" % (stat, p_value))\n",
    "                hypothesis.append(fail_to_reject_H.translate(SUB)) if p_value > alpha else hypothesis.append(reject_H.translate(SUB))\n",
    "                \n",
    "    df_normality_test = pd.DataFrame({\n",
    "                            \"variable\": variable,\n",
    "                            \"normality test\": test_name, \n",
    "                            \"result\": result,\n",
    "                            \"hypothesis\": hypothesis})\n",
    "    \n",
    "    display(df_normality_test)\n",
    "    \n",
    "\n",
    "def highlight_max(data, color=\"yellow\"):\n",
    "    \"\"\" \n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    -----------------  \n",
    "        data (pandas.DataFrame): Dataset to analyze\n",
    "        color (str) : color to highlight into the dataset\n",
    "        \n",
    "    Returns:\n",
    "    -----------------\n",
    "        data (pandas.DataFrame): Dataset analyzed\n",
    "   \"\"\"  \n",
    "    \n",
    "    #attr = 'background-color: {}'.format(color) + 'color: black'\n",
    "    attr = \"background-color: yellow; color: black\"\n",
    "    \n",
    "    #remove % and cast to float\n",
    "    data = data.replace(\"%\",\"\", regex=True).astype(float)\n",
    "    \n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else \"\" for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        \n",
    "        return pd.DataFrame(np.where(is_max, attr, \"\"),\n",
    "                            index=data.index, columns=data.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
